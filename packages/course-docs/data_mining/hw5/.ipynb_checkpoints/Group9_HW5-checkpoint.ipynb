{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EE-361M Introduction to Data Mining\n",
    "## Assignment #5\n",
    "## Due: Thursday, Apr 14, 2016 by 2pm; Total points: 60\n",
    "\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook** (if this isn't possible, let me know). Please use this naming format for your notebook you submit: **Group(Group Num)_HW(HW Number).ipynb**. For example, Group1_HW1.ipynb. Homeworks should be submitted through Canvas in your **groups of 3 from the first homework**. If groups need to be adjusted please contact the TA. Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (1+1+5+3+3+2=15pts) - Logistic Regression\n",
    "\n",
    "In this question we will be predicting whether someone will have an affair! Yes - there is data on this. See below on how to import the data.\n",
    "1. Convert naffairs to a binary variable hadAffair which is 1 if had an affair and zero otherwise\n",
    "2. Split the data into training and test. Use 42 as random seed and use 1/3rd of the data for testing. Our y variable is hadAffair and X matrix includes all the other variables except naffairs.\n",
    "3. Train a logistic regression with almost no regularization (pass l2 (ridge) to penalty and 1,000 to the C parameter which is the inverse of regularization strength lambda. This essentially does l2 regularization but applies very little weight to the penalty term) and report the confusion matrix on the test data. Also report the accuracy for the \"no affairs\" class, the affairs class, and the average per-class accuracy on the test data. Average per-class accuracy is described in this [post](http://blog.dato.com/how-to-evaluate-machine-learning-models-part-2a-classification-metrics).\n",
    "4. Repeat step 3 except use l2 penalty with Cs of [.001, .01,0.1, 1]. You will want to use k-fold cross validation to select the best parameter. To evaluate which parameter is best, maximize the average per-class accuracy. To help with this task, check out [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) and how to make your own [custom scorer](http://scikit-learn.org/stable/modules/model_evaluation.html).\n",
    "5. Repeat question 4 except use l1 (i.e. Lasso) instead of l2 as the penalty type.\n",
    "6. Which model produces the best average per-class accuracy? Why do you think this is the case? How do the models handle the different classes, and why is this so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "df = data('affairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Convert naffairs to a binary variable hadAffair which is 1 if had an affair and zero otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, value in enumerate(df.naffairs):\n",
    "    if value > 0: df.set_value(index, 'naffairs', 1)\n",
    "    else: df.set_value(index, 'naffairs', 0)\n",
    "df.rename(columns={'naffairs':'hadAffair'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Split the data into training and test. Use 42 as random seed and use 1/3rd of the data for testing. Our y variable is hadAffair and X matrix includes all the other variables except naffairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split as split\n",
    "\n",
    "X = df.dropna()\n",
    "y = X['hadAffair']\n",
    "del X['hadAffair']\n",
    "X_train, X_test, y_train, y_test = split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Train a logistic regression with almost no regularization (pass l2 (ridge) to penalty and 1,000 to the C parameter which is the inverse of regularization strength lambda. This essentially does l2 regularization but applies very little weight to the penalty term) and report the confusion matrix on the test data. Also report the accuracy for the \"no affairs\" class, the affairs class, and the average per-class accuracy on the test data. Average per-class accuracy is described in this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  1\n",
      "0  154  1\n",
      "1   44  0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import confusion_matrix as CM\n",
    "import pandas as pd\n",
    "\n",
    "lr = LR(penalty='l2', C=1000)\n",
    "y_pred = lr.fit(X_train, y_train).predict(X_test)\n",
    "cm = pd.DataFrame(CM(y_test, y_pred))\n",
    "print \"Confusion Matrix:\\n%s\\n\" % (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the \"no affairs\" class = 154/(154+1) = 99.35%\n",
    "\n",
    "The accuracy for the \"affairs\" class = 0/(44+0) = 0%\n",
    "\n",
    "The average per-class accuracy = (99.35% + 0%)/2 = 49.68%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Repeat step 3 except use l2 penalty with Cs of [.001, .01,0.1, 1]. You will want to use k-fold cross validation to select the best parameter. To evaluate which parameter is best, maximize the average per-class accuracy. To help with this task, check out GridSearchCV and how to make your own custom scorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for Ridge:\n",
      "{'penalty': 'l2', 'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer as MS\n",
    "from sklearn import grid_search as GS\n",
    "\n",
    "def avg_per_class_acc(truth, prediction):\n",
    "    cm = CM(truth, prediction)\n",
    "    naffair_acc = float(cm[0][0])/float(cm[0][0]+cm[0][1])\n",
    "    affair_acc = float(cm[1][1])/float(cm[1][0]+cm[1][1])\n",
    "    return (naffair_acc+affair_acc)/2\n",
    "\n",
    "my_scorer = MS(avg_per_class_acc)   \n",
    "params1 = {'penalty': ['l2'], 'C': [0.001, 0.01, 0.1, 1]}\n",
    "lr2 = GS.GridSearchCV(estimator=LR(), param_grid=params1, scoring=my_scorer)\n",
    "lr2.fit(X_train, y_train)\n",
    "print \"Best Params for Ridge:\\n%s\" % (lr2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Repeat question 4 except use l1 (i.e. Lasso) instead of l2 as the penalty type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params for Lasso:\n",
      "{'penalty': 'l1', 'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "params2 = {'penalty': ['l1'], 'C': [0.001, 0.01, 0.1, 1]}\n",
    "lr1 = GS.GridSearchCV(estimator=LR(), param_grid=params2, scoring=my_scorer)\n",
    "lr1.fit(X_train, y_train)\n",
    "print \"Best Params for Lasso:\\n%s\" % (lr1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Which model produces the best average per-class accuracy? Why do you think this is the case? How do the models handle the different classes, and why is this so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge avg_per_class_acc: 0.5\n",
      "\n",
      "Lasso avg_per_class_acc: 0.5\n"
     ]
    }
   ],
   "source": [
    "print \"Ridge avg_per_class_acc: %s\\n\" % (lr2.best_score_)\n",
    "print \"Lasso avg_per_class_acc: %s\" % (lr1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models produce the same average per-class accuracy. This is likely due to the fact that Logistic Regression itself does not perform much better, or the same, as the average, no matter what method you use for penalty terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (2+3+2+3=10pts) - Support Vector Classifier\n",
    "\n",
    "This question will continue to use the data from question 1 - including the training and test split data.\n",
    "1. Fit a support vector classifier using the standard options on [sklearn's SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC). Report the confusion matrix on the test data. Also report the accuracy for the no affairs class, the affairs class, and the average per-class accuracy (same as question 1).\n",
    "2. Repeat question 1 except use grid search to select the best value of C within this set: [0.001, 0.01, 0.1, 1,5,10,100] and try both a radial and polynomial kernel (thus trying 14 combinations). Choose the combination that maximizes the average per-class accuracy. Use 5 folds. Report the best model, the confusion matrix, the accuracy for the no affairs class, the affairs class, and the average per-class accuracy.\n",
    "3. Briefly discuss the effect of different  C,  kernel combinations.\n",
    "4. Discuss your results from parts 1 and 2 and mention how they differ from Question 1's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Fit a support vector classifier using the standard options on sklearn's SVC. Report the confusion matrix on the test data. Also report the accuracy for the no affairs class, the affairs class, and the average per-class accuracy (same as question 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "     0  1\n",
      "0  155  0\n",
      "1   44  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "y_pred = svc.fit(X_train, y_train).predict(X_test)\n",
    "cm = pd.DataFrame(CM(y_test, y_pred))\n",
    "print \"Confusion Matrix:\\n%s\\n\" % (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Repeat question 1 except use grid search to select the best value of C within this set: [0.001, 0.01, 0.1, 1,5,10,100] and try both a radial and polynomial kernel (thus trying 14 combinations). Choose the combination that maximizes the average per-class accuracy. Use 5 folds. Report the best model, the confusion matrix, the accuracy for the no affairs class, the affairs class, and the average per-class accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1\n",
      "0  148  7\n",
      "1   40  4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params3 = {'kernel': ['rbf', 'poly'], 'C': [0.001, 0.01, 0.1, 1, 5, 10, 100]}\n",
    "gs = GS.GridSearchCV(estimator=SVC(), param_grid=params3, scoring=my_scorer, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "svc = gs.best_estimator_\n",
    "print \"Best Model:\\n%s\\n\" % (svc)\n",
    "y_pred = svc.fit(X_train, y_train).predict(X_test)\n",
    "cm = pd.DataFrame(CM(y_test, y_pred))\n",
    "print \"Confusion Matrix:\\n%s\\n\" % (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the \"no affairs\" class = 148/(148+7) = 96.73%\n",
    "\n",
    "The accuracy for the \"affairs\" class = 4/(40+4) = 9.10%\n",
    "\n",
    "The average per-class accuracy = (96.73% + 9.10%)/2 = 52.92%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Briefly discuss the effect of different C, kernel combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.50000, std: 0.00000, params: {'kernel': 'rbf', 'C': 0.001},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'poly', 'C': 0.001},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'rbf', 'C': 0.01},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'poly', 'C': 0.01},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'rbf', 'C': 0.1},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'poly', 'C': 0.1},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'rbf', 'C': 1},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'poly', 'C': 1},\n",
       " mean: 0.49325, std: 0.01356, params: {'kernel': 'rbf', 'C': 5},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'poly', 'C': 5},\n",
       " mean: 0.49325, std: 0.01356, params: {'kernel': 'rbf', 'C': 10},\n",
       " mean: 0.50000, std: 0.00000, params: {'kernel': 'poly', 'C': 10},\n",
       " mean: 0.50405, std: 0.01457, params: {'kernel': 'rbf', 'C': 100},\n",
       " mean: 0.49663, std: 0.00678, params: {'kernel': 'poly', 'C': 100}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no effect or change in the accuracy of the C/kernel combinations when C was between 0.001 and 1, always remaining at 50%. When C = 5 and 10, the accuracies lowered slightly below 50% with radial kernel combinations while remaining the same with polynomial kernel combinations. Lastly, when C = 100, the radial kernel combo increased slightly above 50% while the polynomial kernel combo decreased slightly below 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Discuss your results from parts 1 and 2 and mention how they differ from Question 1's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from part 1 were very similar to the results in Question 1, both essentially equal to the average of 50% , i.e. having no predictive power. The results from part 2, however, improved noticibally. Tweaking the SVM hyperparameters allowed for a average per-class accuracy of almost 53%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 (2+1+3+1+3=10pts) - Regression Trees\n",
    "\n",
    "This question is very similar to homework 4 question 1. Except now we will be using regression trees and not classification trees, and you will be addressing a regression problem (i.e., the independent variable \"price\" will not be binarized).\n",
    "\n",
    "For this question, we will be using the housing dataset (see code below). \n",
    "\n",
    "1. Convert driveway, recroom, fullbase, gashw, airco, and prefarea to numeric dummy variables (1 for yes, zero for no)\n",
    "2. Split the data into training and testing with a random seed of 42 and keeping 1/3rd of the data for testing\n",
    "2. Fit a [decision tree regressor](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor) to predict price using all the data (your dummy variables plus bedrooms and bathrooms).\n",
    "5. Report the root MSE on the test data.\n",
    "6. How does the tree decide on a splitting point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data('Housing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 (2+5+3=10pts) - Support Vector Regression\n",
    "\n",
    "This question will continue to use the data from question 3 - including the training and test split data.\n",
    "\n",
    "1. Fit a support vector regression using the standard options on [sklearn's SVR](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Report the root MSE.\n",
    "2. Repeat question 1 except use grid search to select the best value of C within this set: [0.001, 0.01, 0.1, 1,5,10,100] and try both a radial and polynomial kernel (thus trying 14 combinations). Choose the combination that minimizes MSE. Use 5 folds. Report the best model and the test root MSE.\n",
    "4. Discuss your results from parts 1 and 2 and how they differ from Question 3 results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (3+2+2+2+2+2+2=15pts) - Random Forest\n",
    "\n",
    "This question will also continue to use the data from Question 1.\n",
    "1. Fit a random forest model grid searching over the following values: {'n_estimators':[10, 100, 1000], 'max_features': ['auto', 'sqrt', 'log2']}. Choose the combination that maximizes the average per-class accuracy. Use 5 folds. Report the best model, the confusion matrix, the accuracy for the no affairs class, the affairs class, and the average per-class accuracy.\n",
    "2. What do the n_estimators and max_features parameters do?\n",
    "3. Report the features in order of importance based on the model used in part 1\n",
    "4. Repeat question 1 using an AdaBoostClassifier and grid search over the following values: {'n_estimators':[50, 500, 5000], 'learning_rate': [.001, .01, .1]}\n",
    "5. What does the learning_rate parameter do?\n",
    "6. Report the features in order of importance based on the model used in part 4\n",
    "7. Compare the results in part 1 and 4 and questions 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Fit a random forest model grid searching over the following values: {'n_estimators':[10, 100, 1000], 'max_features': ['auto', 'sqrt', 'log2']}. Choose the combination that maximizes the average per-class accuracy. Use 5 folds. Report the best model, the confusion matrix, the accuracy for the no affairs class, the affairs class, and the average per-class accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\n",
      "Confusion Matrix:\n",
      "     0   1\n",
      "0  131  24\n",
      "1   35   9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "parameters = {'n_estimators':[10, 100, 1000], 'max_features': ['auto', 'sqrt', 'log2']}\n",
    "grid = GS.GridSearchCV(estimator=RFC(), param_grid=parameters, scoring=my_scorer, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "rfc = grid.best_estimator_\n",
    "print \"Best Model:\\n%s\\n\" % (rfc)\n",
    "y_pred = rfc.fit(X_train, y_train).predict(X_test)\n",
    "cm = pd.DataFrame(CM(y_test, y_pred))\n",
    "print \"Confusion Matrix:\\n%s\\n\" % (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the \"no affairs\" class = 135/(135+20) = 87.10%\n",
    "\n",
    "The accuracy for the \"affairs\" class = 9/(35+9) = 20.45%\n",
    "\n",
    "The average per-class accuracy = (87.10% + 20.45%)/2 = 53.78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What do the n_estimators and max_features parameters do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.50230, std: 0.02362, params: {'max_features': 'auto', 'n_estimators': 10},\n",
       " mean: 0.50723, std: 0.02288, params: {'max_features': 'auto', 'n_estimators': 100},\n",
       " mean: 0.49988, std: 0.03328, params: {'max_features': 'auto', 'n_estimators': 1000},\n",
       " mean: 0.52654, std: 0.03260, params: {'max_features': 'sqrt', 'n_estimators': 10},\n",
       " mean: 0.49819, std: 0.03559, params: {'max_features': 'sqrt', 'n_estimators': 100},\n",
       " mean: 0.50328, std: 0.04266, params: {'max_features': 'sqrt', 'n_estimators': 1000},\n",
       " mean: 0.51249, std: 0.02969, params: {'max_features': 'log2', 'n_estimators': 10},\n",
       " mean: 0.51104, std: 0.01774, params: {'max_features': 'log2', 'n_estimators': 100},\n",
       " mean: 0.50834, std: 0.03815, params: {'max_features': 'log2', 'n_estimators': 1000}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'n_estimators' refers to the number of the trees in the decision tree forest. 'max_features' refers to the number of features to consider when looking for the best split. For our classification problem, as n_estimators increased and the max_features (method) was held constant, the mean accuracy was affected in a somewhat indeterminate way, sometimes going slightly up or down. For max_features, the mean accuracy, in general, increased or decreased in a consistent manor from between \"auto\", \"sqrt\", and \"log2\" as n_estimators was held constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Report the features in order of importance based on the model used in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in order of decreasing importance:\n",
      "['kids', 'notrel', 'yrsmarr4', 'smerel', 'slghtrel', 'vryhap', 'yrsmarr3', 'yrsmarr2', 'yrsmarr6', 'avgmarr', 'yrsmarr5', 'antirel', 'yrsmarr1', 'hapavg', 'vryrel', 'unhap', 'vryunhap']\n"
     ]
    }
   ],
   "source": [
    "imp = rfc.feature_importances_\n",
    "order_importance = sorted(range(len(imp)), key=lambda k: imp[k])[::-1]\n",
    "for i in range(len(X.columns)):\n",
    "    order_importance[i] = X.columns[order_importance[i]]\n",
    "print \"Features in order of decreasing importance:\\n%s\" % (order_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Repeat question 1 using an AdaBoostClassifier and grid search over the following values: { 'n_estimators': [50, 500, 5000], 'learning_rate': [.001, .01, .1] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.001, n_estimators=50, random_state=None)\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1\n",
      "0  155  0\n",
      "1   44  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "\n",
    "parameters = {'n_estimators': [50, 500, 5000], 'learning_rate': [.001, .01, .1]}\n",
    "grid = GS.GridSearchCV(estimator=ABC(), param_grid=parameters, scoring=my_scorer, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "abc = grid.best_estimator_\n",
    "print \"Best Model:\\n%s\\n\" % (abc)\n",
    "y_pred = abc.fit(X_train, y_train).predict(X_test)\n",
    "cm = pd.DataFrame(CM(y_test, y_pred))\n",
    "print \"Confusion Matrix:\\n%s\\n\" % (cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the \"no affairs\" class = 155/(155+0) = 100%\n",
    "\n",
    "The accuracy for the \"affairs\" class = 0/(44+0) = 0%\n",
    "\n",
    "The average per-class accuracy = (100% + 0%)/2 = 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What does the learning_rate parameter do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.49325, std: 0.01356, params: {'n_estimators': 50, 'learning_rate': 0.001},\n",
       " mean: 0.49325, std: 0.01356, params: {'n_estimators': 500, 'learning_rate': 0.001},\n",
       " mean: 0.49325, std: 0.01356, params: {'n_estimators': 5000, 'learning_rate': 0.001},\n",
       " mean: 0.49325, std: 0.01356, params: {'n_estimators': 50, 'learning_rate': 0.01},\n",
       " mean: 0.49325, std: 0.01356, params: {'n_estimators': 500, 'learning_rate': 0.01},\n",
       " mean: 0.49325, std: 0.01356, params: {'n_estimators': 5000, 'learning_rate': 0.01},\n",
       " mean: 0.49325, std: 0.01356, params: {'n_estimators': 50, 'learning_rate': 0.1},\n",
       " mean: 0.49325, std: 0.01356, params: {'n_estimators': 500, 'learning_rate': 0.1},\n",
       " mean: 0.49325, std: 0.01356, params: {'n_estimators': 5000, 'learning_rate': 0.1}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning_rate parameter is the factor the contribution of each classifier is shrunk. For our classification problem, the learning_rate seemed to have no effect whatsoever on our mean accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Report the features in order of importance based on the model used in part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in order of decreasing importance:\n",
      "['unhap', 'yrsmarr6', 'yrsmarr5', 'yrsmarr4', 'yrsmarr3', 'yrsmarr2', 'yrsmarr1', 'vryrel', 'smerel', 'slghtrel', 'notrel', 'antirel', 'vryhap', 'hapavg', 'avgmarr', 'vryunhap', 'kids']\n"
     ]
    }
   ],
   "source": [
    "imp = abc.feature_importances_\n",
    "order_importance = sorted(range(len(imp)), key=lambda k: imp[k])[::-1]\n",
    "for i in range(len(X.columns)):\n",
    "    order_importance[i] = X.columns[order_importance[i]]\n",
    "print \"Features in order of decreasing importance:\\n%s\" % (order_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Compare the results in part 1 and 4 and questions 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average per-class accuracy for the best RandomForestClassifier model was 53.78%, which was the best score of any model tested in the HW. The AdaBoostClassifer unfortunately did not have any significant predictive power, with its average per-class accuracy being 50%. As you would expect, the order of importance for the features were very different between the two, with the RFC even having its most important feature as \"kids\" and ABC having it as its least important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
