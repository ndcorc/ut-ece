{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "from sklearn.preprocessing import LabelEncoder as LE\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from scipy import sparse\n",
    "from itertools import combinations\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    X = pd.read_csv(\"../dataset/train.csv\")\n",
    "    X_test = pd.read_csv(\"../dataset/test.csv\")\n",
    "    return X, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_target(X, X_test):\n",
    "    y = X.ACTION\n",
    "    del X['ACTION']\n",
    "    IDs = X_test.id\n",
    "    del X_test['id']\n",
    "    return y, IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"../dataset/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summarization/Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_ones(X):\n",
    "    \"\"\"\n",
    "    Counts the number of 1-count categories in each feature\n",
    "    \"\"\"\n",
    "    value_counts = dict()\n",
    "    for c in all_data.columns:\n",
    "        value_counts[c] = pd.Series(all_data[c].value_counts())\n",
    "    ones = list()\n",
    "    for c in X.columns:\n",
    "        for i, v in value_counts[c].iteritems():\n",
    "            if v == 1: ones.append(i)               \n",
    "    return ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot(all_data):\n",
    "#    all_data = pd.get_dummies(pd.concat([X, X_test], ignore_index=True))\n",
    "#    all_data = pd.concat([X, X_test], ignore_index=True)\n",
    "    enc = OneHotEncoder()\n",
    "    final_data = pd.DataFrame(enc.fit_transform(all_data))\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_separate(data):\n",
    "    keys = []\n",
    "    for c in data.T:\n",
    "        uniques = set(list(c))\n",
    "        keys.append(dict((key, i) for i, key in enumerate(uniques)))\n",
    "    total = data.shape[0]\n",
    "    hot_data = []\n",
    "    for i, c in enumerate(data.T):\n",
    "        kmap = keys[i]\n",
    "        num_labels = len(kmap)\n",
    "        spmat = sparse.lil_matrix((total, num_labels))\n",
    "        for j, val in enumerate(c):\n",
    "            if val in kmap:\n",
    "                    spmat[j, kmap[val]] = 1\n",
    "        hot_data.append(spmat)\n",
    "    hot_data = sparse.hstack(hot_data).tocsr()\n",
    "    return hot_data, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_ones(data):\n",
    "    ones = list()\n",
    "    for c in data.columns:\n",
    "        if data[c].sum() == 1:\n",
    "            ones.append(c)\n",
    "    return data.drop(ones, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def group_data(data, degree=3, hash=hash):\n",
    "    \"\"\"   \n",
    "    Groups all columns of data into all combinations of triples\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    m,n = data.shape\n",
    "    for indicies in combinations(range(n), degree):\n",
    "        if 5 in indicies and 7 in indicies:\n",
    "            pass\n",
    "        elif 2 in indicies and 3 in indicies:\n",
    "            pass\n",
    "        else:\n",
    "            new_data.append([hash(tuple(v)) for v in data[:,indicies]])\n",
    "    return np.array(new_data).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Not Preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsvc = svm.LinearSVC()\n",
    "y_pred = pd.DataFrame(lsvc.fit(X, y).predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred.columns = ['ACTION']\n",
    "test1 = pd.concat([IDs, y_pred], axis=1)\n",
    "test1.to_csv(\"../results/test1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Parameters Evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search as GS\n",
    "\n",
    "parameters = {'C':[0.1, 1, 10, 100, 1000], 'loss': ['squared_hinge', 'hinge']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessed (Initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([X, X_test], ignore_index=True)\n",
    "final_data = one_hot(all_data)\n",
    "\n",
    "final_data = drop_ones(final_data)\n",
    "X, X_test = final_data[:32769], final_data[32769:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946273349362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cross_validation import train_test_split as split\n",
    "X_train, X_val, y_train, y_val = split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "lsvc = svm.LinearSVC()\n",
    "lsvc.fit(X_train, y_train)\n",
    "score = lsvc.score(X_val, y_val)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(lsvc.fit(X, y).predict(X_test))\n",
    "y_pred.columns = ['ACTION']\n",
    "test2 = pd.concat([IDs, y_pred], axis=1)\n",
    "test2.to_csv(\"../results/test2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## New Approach With Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_test = get_data()\n",
    "all_data = np.vstack((X.ix[:,1:-1], X_test.ix[:,1:-1]))\n",
    "num_train = np.shape(X)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Label Encoder Initially Instead of One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LE()\n",
    "for column in range(all_data.shape[1]):\n",
    "    le.fit(all_data[:, column])\n",
    "    all_data[:, column] = le.transform(all_data[:, column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get First Order Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in range(all_data.shape[1]):\n",
    "    le.fit(all_data[:, c])\n",
    "    all_data[:, c] = le.transform(all_data[:, c])\n",
    "    uniques = len(set(all_data[:,c]))\n",
    "    maximum = max(all_data[:,c])\n",
    "    if maximum < 65534:\n",
    "        count_map = np.bincount((all_data[:, c]).astype('uint16'))\n",
    "        for n,i in enumerate(all_data[:, c]):\n",
    "            if count_map[i] <= 1:\n",
    "                all_data[n, c] = uniques\n",
    "            elif count_map[i] == 2:\n",
    "                all_data[n, c] = uniques+1\n",
    "    else:\n",
    "        for n,i in enumerate(all_data[:, c]):\n",
    "            if (all_data[:, c] == i).sum() <= 1:\n",
    "                all_data[n, c] = uniques\n",
    "            elif (all_data[:, c] == i).sum() == 2:\n",
    "                all_data[n, c] = uniques+1\n",
    "    uniques = len(set(all_data[:,c]))\n",
    "    le.fit(all_data[:, c])\n",
    "    all_data[:, c] = le.transform(all_data[:, c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Second Order Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sec = group_data(all_data, degree=2) \n",
    "for c in range(sec.shape[1]):\n",
    "    le.fit(sec[:, c])\n",
    "    sec[:, c] = le.transform(sec[:, c])\n",
    "    uniques = len(set(sec[:,c]))\n",
    "    maximum = max(sec[:,c])\n",
    "    if maximum < 65534:\n",
    "        count_map = np.bincount((sec[:, c]).astype('uint16'))\n",
    "        for n,i in enumerate(sec[:, c]):\n",
    "            if count_map[i] <= 1:\n",
    "                sec[n, c] = uniques\n",
    "            elif count_map[i] == 2:\n",
    "                sec[n, c] = uniques+1\n",
    "    else:\n",
    "        for n,i in enumerate(sec[:, c]):\n",
    "            if (sec[:, c] == i).sum() <= 1:\n",
    "                sec[n, c] = uniques\n",
    "            elif (sec[:, c] == i).sum() == 2:\n",
    "                sec[n, c] = uniques+1\n",
    "    uniques = len(set(sec[:,c]))\n",
    "    le.fit(sec[:, c])\n",
    "    sec[:, c] = le.transform(sec[:, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "third = group_data(all_data, degree=3)\n",
    "for c in range(third.shape[1]):\n",
    "    le.fit(third[:, c])\n",
    "    third[:, c] = le.transform(third[:, c])\n",
    "    uniques = len(set(third[:,c]))\n",
    "    maximum = max(third[:,c])\n",
    "    if maximum < 65534:\n",
    "        count_map = np.bincount((third[:, c]).astype('uint16'))\n",
    "        for n,i in enumerate(third[:, c]):\n",
    "            if count_map[i] <= 1:\n",
    "                third[n, c] = uniques\n",
    "            elif count_map[i] == 2:\n",
    "                third[n, c] = uniques+1\n",
    "    else:\n",
    "        for n,i in enumerate(third[:, c]):\n",
    "            if (third[:, c] == i).sum() <= 1:\n",
    "                third[n, c] = uniques\n",
    "            elif (third[:, c] == i).sum() == 2:\n",
    "                third[n, c] = uniques+1\n",
    "    uniques = len(set(third[:,c]))\n",
    "    le.fit(third[:, c])\n",
    "    third[:, c] = le.transform(third[:, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect the training features together\n",
    "y = np.array(X.ACTION)\n",
    "X = all_data[:num_train]\n",
    "X_2 = sec[:num_train]\n",
    "X_3 = third[:num_train]\n",
    "\n",
    "# Collect the testing features together\n",
    "X_test = all_data[num_train:]\n",
    "X_test_2 = sec[num_train:]\n",
    "X_test_3 = third[num_train:]\n",
    "\n",
    "allX_train = np.hstack((X, X_2, X_3))\n",
    "allX_test = np.hstack((X_test, X_test_2, X_test_3))\n",
    "num_features = allX_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_hot = [one_hot_separate(allX_train[:,[i]])[0] for i in range(num_features)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Feature Selection Using AUC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LR(class_weight='balanced', penalty='l2')\n",
    "\n",
    "def cv_loop(X, y, model, N):\n",
    "    mean_auc = 0.\n",
    "    for i in range(N):\n",
    "        X_train, X_cv, y_train, y_cv = cv.train_test_split(\n",
    "                                       X, y, test_size=1.0/float(N), \n",
    "                                       random_state = i*SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict_proba(X_cv)[:,1]\n",
    "        auc = metrics.roc_auc_score(y_cv, preds)\n",
    "        mean_auc += auc\n",
    "    return mean_auc/N    \n",
    "\n",
    "score_hist = []\n",
    "N = 10\n",
    "good_features = set([])\n",
    "# Greedy feature selection loop\n",
    "while len(score_hist) < 2 or score_hist[-1][0] > score_hist[-2][0]:\n",
    "    scores = []\n",
    "    for f in range(len(X_hot)):\n",
    "        if f not in good_features:\n",
    "            feats = list(good_features) + [f]\n",
    "            X_partial = sparse.hstack([X_hot[j] for j in feats]).tocsr()\n",
    "            score = cv_loop(X_partial, y, lr, N)\n",
    "            scores.append((score, f))\n",
    "    good_features.add(sorted(scores)[-1][1])\n",
    "    score_hist.append(sorted(scores)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features [0, 7, 8, 28, 34, 36, 50, 60, 61, 62, 64, 69]\n"
     ]
    }
   ],
   "source": [
    "# Remove last added feature from good_features\n",
    "good_features.remove(score_hist[-1][1])\n",
    "good_features = sorted(list(good_features))\n",
    "print \"Selected features %s\" % good_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for best hyperparams (not technically sklearn's grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.031250 Mean AUC: 0.909181\n",
      "C: 0.067504 Mean AUC: 0.909181\n",
      "C: 0.145816 Mean AUC: 0.909181\n",
      "C: 0.314980 Mean AUC: 0.909181\n",
      "C: 0.680395 Mean AUC: 0.909181\n",
      "C: 1.469734 Mean AUC: 0.909181\n",
      "C: 3.174802 Mean AUC: 0.909181\n",
      "C: 6.857952 Mean AUC: 0.909181\n",
      "C: 14.813995 Mean AUC: 0.909181\n",
      "C: 32.000000 Mean AUC: 0.909181\n",
      "Best C value: 32.000000\n"
     ]
    }
   ],
   "source": [
    "score_hist = []\n",
    "X_partial = sparse.hstack([X_hot[j] for j in good_features]).tocsr()\n",
    "C_list = np.logspace(-5, 5, 10, base=2)\n",
    "for C in C_list:\n",
    "    score = cv_loop(X_partial, y, lr, N)\n",
    "    score_hist.append((score,C))\n",
    "    print \"C: %f Mean AUC: %f\" %(C, score)\n",
    "bestC = sorted(score_hist)[-1][1]\n",
    "print \"Best C value: %f\" % (bestC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_best_feats = np.vstack((allX_train[:,good_features], allX_test[:,good_features]))\n",
    "X_best_feats, keymap = one_hot_separate(X_best_feats)\n",
    "X_train = X_best_feats[:num_train]\n",
    "X_test = X_best_feats[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LR(C=bestC, class_weight='balanced', penalty='l2')\n",
    "model.fit(X_train, y)\n",
    "preds = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "content = ['id,ACTION']\n",
    "for i, p in enumerate(preds):\n",
    "    content.append('%i,%f' %(i+1,p))\n",
    "f = open(\"finalTestSubmission.csv\", 'w')\n",
    "f.write('\\n'.join(content))\n",
    "f.close()\n",
    "preds = model.predict_proba(X_train)[:,1]\n",
    "content = ['id,ACTION']\n",
    "for i, p in enumerate(preds):\n",
    "    content.append('%i,%f' %(i+1,p))\n",
    "f = open(\"finalTrainSubmission.csv\", 'w')\n",
    "f.write('\\n'.join(content))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
